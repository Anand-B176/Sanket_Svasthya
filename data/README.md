# Dataset Information

## ğŸ“Š Overview

This project uses the **Medical Sign Language Dataset** for healthcare communication.

---

## ğŸ“ Dataset Sources

### Primary Dataset
- **Name:** Indian Medical Sign Language Dataset
- **Source:** Provided by competition organizers
- **Signs:** 55 medical signs (54 available, Sign_30 missing)
- **Performers:** 16 performers Ã— 2 takes each
- **Format:** Video frames (JPG) + Kinect skeleton (CSV)

### Secondary Dataset (ISL Alphabets)
- **Name:** Indian Sign Language Alphabet Dataset
- **Signs:** 25 letters (A-Y, excluding J)
- **Format:** Pre-extracted NumPy arrays

---

## ğŸ“ˆ Dataset Statistics

| Metric | Value |
|--------|-------|
| Total Signs | 54 (medical) + 25 (alphabets) |
| Total Samples | 1,728 (medical) + 625 (alphabets) |
| Performers | 16 |
| Takes per Performer | 2 |
| Frames per Sample | 50-150 (variable) |
| Feature Dimension | 1,662 (MediaPipe Holistic) |

---

## ğŸ“‚ Data Organization

```
Original Dataset Structure:
Signs(1-5)/
â”œâ”€â”€ Sign_01_Performer_01_1/
â”‚   â”œâ”€â”€ 01 Times/
â”‚   â”œâ”€â”€ 02 Color Frames/        # â† Used for feature extraction
â”‚   â”œâ”€â”€ 03 Infrared Frames/
â”‚   â”œâ”€â”€ 04 Depth Frames/
â”‚   â”œâ”€â”€ 05 BodyIndex Frames/
â”‚   â”œâ”€â”€ 06 Body Skels data/     # Kinect skeleton (not used)
â”‚   â””â”€â”€ 07 Color Body Frames/
...
```

---

## ğŸ”„ Preprocessing Pipeline

1. **Extract Color Frames** from dataset folders
2. **Process with MediaPipe Holistic** â†’ 1,662 features/frame
3. **Apply Nose-Centered Normalization** â†’ Translation invariance
4. **Pad/Truncate to 30 frames** â†’ Fixed sequence length
5. **Save as NumPy arrays** â†’ `.npy` files

---

## âš ï¸ Data Notes

- **Sign_30 is missing** from the original dataset
- Model trained on 54 classes instead of 55
- Augmentation applied (3Ã— dataset size)
- 80/20 train/test split with stratification

---

## ğŸ“¥ Download Instructions

The processed data is too large for GitHub. Download from:

**Google Drive:** [Link to be added after upload]

After downloading, place files in:
```
data/processed/
â”œâ”€â”€ X_train.npy
â”œâ”€â”€ y_train.npy
â”œâ”€â”€ X_test.npy
â”œâ”€â”€ y_test.npy
â””â”€â”€ classes.npy
```
